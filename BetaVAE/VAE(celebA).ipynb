{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.utils import make_grid, save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 64\n",
    "batch_size = 100\n",
    "num_threads = 8\n",
    "lat_dim = 32\n",
    "lr = 1e-4\n",
    "n_epoch = 10\n",
    "beta = 1\n",
    "\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CelabA_loader():\n",
    "    # For cropped images, use below transform\n",
    "    #transform = transforms.Compose([transforms.CenterCrop(size=(170, 130)), transforms.Resize(size=(img_size, img_size)), transforms.ToTensor()])\n",
    "    transform = transforms.Compose([transforms.Resize(size=(img_size, img_size)), transforms.ToTensor()])\n",
    "    train_data = torchvision.datasets.ImageFolder(root='data/celebA/', transform=transform)\n",
    "    train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=num_threads, drop_last=True)\n",
    "    test_data = torchvision.datasets.ImageFolder(root='data/celebA/', transform=transform)\n",
    "    test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=num_threads, drop_last=True)\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ELBO_curve(generated, train_list, test_list):\n",
    "    fig = plt.figure()       \n",
    "    plt.plot(train_list, 'r-', label='train ELBO')\n",
    "    plt.plot(test_list, 'r--', label='test ELBO')\n",
    "    plt.legend()\n",
    "    #plt.xscale('log')\n",
    "    plt.savefig('plots/'+generated+'/ELBO_curve.png')\n",
    "    plt.close()\n",
    "\n",
    "def plot_test_images(sample_hat, generated, n, height=img_size, width=img_size):\n",
    "    sample_hat = sample_hat.view(-1, 3, height, width)\n",
    "    grid = save_image(sample_hat, filename=\"plots/\"+generated+\"/test_image.png\", nrow=n, padding=0)\n",
    "    \n",
    "def plot_latent_traverse(model, image_size, traverse_dim, generated, z_mu, intNumX1=7, n=5):\n",
    "    x1s = np.linspace(-3.0, 3.0, intNumX1, dtype=np.float32)\n",
    "    dist = torch.distributions.normal.Normal(loc=0, scale=1)    \n",
    "    canvas = np.zeros((image_size * n, image_size * intNumX1, 3))\n",
    "    \n",
    "    for j in range(n):\n",
    "        for i, x1 in enumerate(x1s):\n",
    "            z_mu[j][traverse_dim] = torch.Tensor([x1])\n",
    "            z_mu = z_mu.to(device)\n",
    "            z = model(z_mu[j]).detach().to(torch.device(\"cpu\"))\n",
    "            z = z.view(3, image_size, image_size)\n",
    "            z = z.permute(1,2,0).numpy()\n",
    "            canvas[image_size*(n-j-1):image_size*(n-j), image_size*i:image_size*(i+1), :] = z\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(canvas)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"plots/\"+generated+\"/latent/latent_traverse_{}.png\".format(traverse_dim), bbox_inches='tight')\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class View(nn.Module):\n",
    "    def __init__(self, size):\n",
    "        super(View, self).__init__()\n",
    "        self.size = size\n",
    "\n",
    "    def forward(self, tensor):\n",
    "        return tensor.view(self.size)\n",
    "\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, generated='Gaussian', mode='learn'):\n",
    "        super(VAE, self).__init__()\n",
    "        self.generated = generated\n",
    "        self.mode = mode\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.encoder = nn.Sequential(nn.Conv2d(3, 32, 4, stride=2, padding=1),  # B*32*32*32\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.Conv2d(32, 32, 4, stride=2, padding=1),  # B*32*16*16\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.Conv2d(32, 64, 4, stride=2, padding=1),  # B*64*8*8\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.Conv2d(64, 64, 4, stride=2, padding=1),  # B*64*4*4\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.Conv2d(64, 256, 4),  # B*256*1*1\n",
    "                                     nn.ReLU(),\n",
    "                                     View(size=(-1, 256)),  # B*256\n",
    "                                     nn.Linear(256, lat_dim*2))\n",
    "\n",
    "        self.decoder = nn.Sequential(nn.Linear(lat_dim, 256),\n",
    "                                     View((-1, 256, 1, 1)),  # B*256*1*1\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.ConvTranspose2d(256, 64, 4),  # B*64*4*4\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.ConvTranspose2d(64, 64, 4, stride=2, padding=1),  # B*64*8*8\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.ConvTranspose2d(64, 32, 4, stride=2, padding=1),  # B*32*16*16\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.ConvTranspose2d(32, 32, 4, stride=2, padding=1),  # B*32*32*32\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.ConvTranspose2d(32, 6, 4, stride=2, padding=1))   # B*3*64*64\n",
    "\n",
    "    def reparametrize(self, z_mu, z_log_var):\n",
    "        std = torch.exp(0.5 * z_log_var)\n",
    "        eps = torch.randn(std.size()).to(device)\n",
    "        return z_mu + std * eps\n",
    "\n",
    "    def encoderNet(self, x):\n",
    "        code = self.encoder(x)\n",
    "        z_mu = code[:, :lat_dim]\n",
    "        z_log_var = code[:, lat_dim:]\n",
    "        z = self.reparametrize(z_mu, z_log_var)\n",
    "        self.kl = -0.5 * ((1 + z_log_var) - z_mu * z_mu - torch.exp(z_log_var)).mean(dim=0).sum()\n",
    "        return z\n",
    "\n",
    "    def decoderNet(self, z):\n",
    "        h = self.decoder(z)\n",
    "        if self.generated == 'Bernoulli':\n",
    "            h_ = h[:, :3, :, :]  \n",
    "            self.x_ = self.sigmoid(h_)\n",
    "            \n",
    "        elif self.generated == 'Gaussian':\n",
    "            x_mu = h[:, :3, :, :]\n",
    "            x_log_var = h[:, 3:, :, :]\n",
    "            x_std = torch.exp(0.5 * x_log_var)\n",
    "            self.dist = torch.distributions.normal.Normal(loc=x_mu, scale=x_std)\n",
    "            self.x_ = self.dist.sample()\n",
    "            # For cleaner images, use below mu_estimation\n",
    "            #self.x_ = x_mu\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.mode == 'learn':\n",
    "            self.z = self.encoderNet(x)\n",
    "            self.decoderNet(self.z)\n",
    "            if self.generated == 'Bernoulli':\n",
    "                self.recon = -(x * torch.log(self.x_ + 1e-10) + (1 - x) * torch.log(1 - self.x_ + 1e-10)).mean(dim=0).sum()\n",
    "            elif self.generated == 'Gaussian':\n",
    "                self.recon = -self.dist.log_prob(x).mean(dim=0).sum()\n",
    "            return self.x_, self.recon, self.kl\n",
    "\n",
    "        elif self.mode == 'generate':\n",
    "            self.decoderNet(x)\n",
    "            return self.x_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CelebA_main(dist='Gaussian'):\n",
    "    train_loader, test_loader = CelabA_loader()\n",
    "    model = VAE(generated=dist).to(device)\n",
    "    model.load_state_dict(torch.load('models/'+dist+'/VAE.pt'))    \n",
    "    model.mode = 'learn'\n",
    "    #for name, param in model.named_parameters():\n",
    "    #    if param.requires_grad:\n",
    "    #        print(name)\n",
    "    \n",
    "    train_list, test_list = [], []\n",
    "    \n",
    "    for epoch in range(n_epoch):\n",
    "        #if (epoch+1) % 200 == 0:\n",
    "        #    lr = lr * 0.1\n",
    "        #    print('current learning rate is ', lr)\n",
    "        optimizer = optim.Adagrad(model.parameters(), lr=lr)\n",
    "        \n",
    "        train_loss, recon_err, kl_div, test_loss = 0.0, 0.0, 0.0, 0.0\n",
    "        cnt = 0\n",
    "        for x, y in train_loader:\n",
    "            cnt += 1\n",
    "            inputs = x.to(device)\n",
    "            new_batch_size = x.size()[0]\n",
    "            inputs = inputs.view(new_batch_size, -1, img_size, img_size)\n",
    "            \n",
    "            _, recon, kl = model(inputs)\n",
    "            loss = recon + beta * kl\n",
    "            \n",
    "            train_loss += loss * new_batch_size / batch_size\n",
    "            recon_err += recon * new_batch_size / batch_size\n",
    "            kl_div += kl * new_batch_size / batch_size\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "      \n",
    "        train_loss = train_loss / cnt\n",
    "        recon_err = recon_err / cnt\n",
    "        kl_div = kl_div / cnt\n",
    "        \n",
    "        train_list.append(-train_loss)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            cnt = 0\n",
    "            for x, y in test_loader:\n",
    "                cnt += 1\n",
    "                model.eval()\n",
    "                inputs = x.to(device)\n",
    "                new_batch_size = x.size()[0]\n",
    "                inputs = inputs.view(new_batch_size, -1, img_size, img_size)\n",
    "            \n",
    "                _, recon, kl = model(inputs)\n",
    "                loss = recon + beta * kl\n",
    "           \n",
    "                test_loss += loss * new_batch_size / batch_size\n",
    "\n",
    "            test_loss = test_loss / cnt\n",
    "            test_list.append(-test_loss)\n",
    "        \n",
    "        torch.save(model.state_dict(), 'models/'+dist+'/VAE.pt')   \n",
    "        \n",
    "        if (epoch+1) % 1 == 0:\n",
    "            print('[Epoch %d] train_loss: %.3f, recon_err: %.3f, kl_div: %.3f, test_loss: %.3f'\n",
    "                  % (epoch+1, train_loss, recon_err, kl_div, test_loss))\n",
    "    \n",
    "    #torch.save(inputs[0:5], 'data/celebA/samples.pt')\n",
    "    \n",
    "    sample = inputs\n",
    "    sample_hat, _, _ = model(sample)\n",
    "            \n",
    "    plot_test_images(sample_hat.detach(), model.generated, n=10)\n",
    "    \n",
    "    plot_ELBO_curve(model.generated, train_list, test_list)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(device)\n",
    "lr = 1e-4\n",
    "n_epoch = 1\n",
    "CelebA_main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(device)\n",
    "model = VAE('Gaussian').to(device)\n",
    "model.load_state_dict(torch.load('models/Gaussian/VAE.pt'))\n",
    "\n",
    "sample = torch.load('data/celebA/samples.pt')\n",
    "\n",
    "for i in range(lat_dim):    \n",
    "    model.mode = 'generate'\n",
    "    z_mu = model.encoderNet(sample)\n",
    "    plot_latent_traverse(model, img_size, i, model.generated, z_mu)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}