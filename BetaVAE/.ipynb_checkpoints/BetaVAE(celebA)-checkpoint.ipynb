{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# importing modules\n",
    "\n",
    "\n",
    "import pickle\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.utils import make_grid, save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting hyperparameters\n",
    "\n",
    "\n",
    "img_size = 32\n",
    "batch_size = 100\n",
    "num_threads = 8\n",
    "lat_dim = 32\n",
    "lr = 1e-4\n",
    "n_epoch = 10\n",
    "beta = 250\n",
    "\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loader for CelebA dataset\n",
    "\n",
    "\n",
    "def CelabA_loader():\n",
    "    # For cropped image, use the below transform\n",
    "    #transform = transforms.Compose([transforms.CenterCrop(size=(170, 130)), transforms.Resize(size=(img_size, img_size)), transforms.ToTensor()])\n",
    "    transform = transforms.Compose([transforms.Resize(size=(img_size, img_size)), transforms.ToTensor()])\n",
    "    dataset = torchvision.datasets.ImageFolder(root='data/celebA/', transform=transform)\n",
    "    \n",
    "    train_data = torchvision.datasets.ImageFolder(root='data/celebA/', transform=transform)\n",
    "    train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=num_threads, drop_last=True)\n",
    "    test_data = torchvision.datasets.ImageFolder(root='data/celebA/', transform=transform)\n",
    "    test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=num_threads, drop_last=True)\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ImageFolder\n",
      "    Number of datapoints: 100\n",
      "    Root location: data/celebA/\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               Resize(size=(32, 32), interpolation=PIL.Image.BILINEAR)\n",
      "               ToTensor()\n",
      "           )\n",
      "[tensor([[[[0.0784, 0.0824, 0.0863,  ..., 0.7137, 0.6706, 0.7412],\n",
      "          [0.0784, 0.0824, 0.0863,  ..., 0.7059, 0.6784, 0.7373],\n",
      "          [0.0784, 0.0824, 0.0824,  ..., 0.7098, 0.6745, 0.7412],\n",
      "          ...,\n",
      "          [0.7647, 0.7569, 0.7569,  ..., 0.2471, 0.3216, 0.3725],\n",
      "          [0.7647, 0.7608, 0.7608,  ..., 0.1765, 0.1451, 0.1647],\n",
      "          [0.7725, 0.7647, 0.7608,  ..., 0.1647, 0.1176, 0.1333]],\n",
      "\n",
      "         [[0.1569, 0.1647, 0.1686,  ..., 0.4824, 0.1843, 0.5098],\n",
      "          [0.1569, 0.1647, 0.1686,  ..., 0.4471, 0.1882, 0.5529],\n",
      "          [0.1569, 0.1647, 0.1686,  ..., 0.4118, 0.1961, 0.5922],\n",
      "          ...,\n",
      "          [0.7490, 0.7412, 0.7412,  ..., 0.2471, 0.3216, 0.3725],\n",
      "          [0.7490, 0.7451, 0.7451,  ..., 0.1804, 0.1451, 0.1608],\n",
      "          [0.7569, 0.7490, 0.7451,  ..., 0.1686, 0.1137, 0.1255]],\n",
      "\n",
      "         [[0.1098, 0.1020, 0.0980,  ..., 0.4588, 0.1216, 0.5020],\n",
      "          [0.1098, 0.0980, 0.0980,  ..., 0.4196, 0.1333, 0.5451],\n",
      "          [0.1098, 0.1020, 0.0980,  ..., 0.3843, 0.1451, 0.5843],\n",
      "          ...,\n",
      "          [0.7451, 0.7373, 0.7412,  ..., 0.2549, 0.3294, 0.3804],\n",
      "          [0.7451, 0.7412, 0.7412,  ..., 0.1922, 0.1529, 0.1686],\n",
      "          [0.7529, 0.7451, 0.7412,  ..., 0.1882, 0.1216, 0.1294]]],\n",
      "\n",
      "\n",
      "        [[[0.9490, 0.9490, 0.9490,  ..., 0.9490, 0.9490, 0.9490],\n",
      "          [0.9490, 0.9490, 0.9490,  ..., 0.9490, 0.9490, 0.9490],\n",
      "          [0.9490, 0.9490, 0.9490,  ..., 0.9490, 0.9490, 0.9490],\n",
      "          ...,\n",
      "          [0.9647, 0.9647, 0.9647,  ..., 0.5451, 0.5451, 0.5882],\n",
      "          [0.9569, 0.9608, 0.9569,  ..., 0.5765, 0.5529, 0.5373],\n",
      "          [0.9451, 0.9451, 0.8392,  ..., 0.5608, 0.5804, 0.5490]],\n",
      "\n",
      "         [[0.9294, 0.9294, 0.9294,  ..., 0.9294, 0.9294, 0.9294],\n",
      "          [0.9294, 0.9294, 0.9294,  ..., 0.9294, 0.9294, 0.9294],\n",
      "          [0.9294, 0.9294, 0.9294,  ..., 0.9294, 0.9294, 0.9294],\n",
      "          ...,\n",
      "          [0.9451, 0.9451, 0.9451,  ..., 0.5412, 0.5412, 0.5843],\n",
      "          [0.9412, 0.9451, 0.9412,  ..., 0.5765, 0.5529, 0.5373],\n",
      "          [0.9333, 0.9333, 0.8275,  ..., 0.5608, 0.5804, 0.5490]],\n",
      "\n",
      "         [[0.9137, 0.9137, 0.9137,  ..., 0.9176, 0.9176, 0.9176],\n",
      "          [0.9137, 0.9137, 0.9137,  ..., 0.9176, 0.9176, 0.9176],\n",
      "          [0.9137, 0.9137, 0.9137,  ..., 0.9176, 0.9176, 0.9176],\n",
      "          ...,\n",
      "          [0.9294, 0.9294, 0.9294,  ..., 0.5255, 0.5294, 0.5686],\n",
      "          [0.9255, 0.9255, 0.9216,  ..., 0.5686, 0.5451, 0.5294],\n",
      "          [0.9137, 0.9137, 0.8078,  ..., 0.5529, 0.5725, 0.5412]]],\n",
      "\n",
      "\n",
      "        [[[0.9922, 0.9882, 0.9843,  ..., 0.9804, 0.9765, 0.9725],\n",
      "          [0.9922, 0.9882, 0.9843,  ..., 0.9804, 0.9765, 0.9725],\n",
      "          [0.9922, 0.9882, 0.9843,  ..., 0.9804, 0.9765, 0.9725],\n",
      "          ...,\n",
      "          [0.9725, 0.9216, 0.7412,  ..., 0.6471, 0.8549, 0.9412],\n",
      "          [0.7020, 0.4745, 0.3294,  ..., 0.2039, 0.3569, 0.5647],\n",
      "          [0.2980, 0.2863, 0.2902,  ..., 0.1451, 0.1647, 0.1843]],\n",
      "\n",
      "         [[0.8275, 0.8235, 0.8196,  ..., 0.7608, 0.7569, 0.7529],\n",
      "          [0.8275, 0.8235, 0.8196,  ..., 0.7608, 0.7569, 0.7529],\n",
      "          [0.8235, 0.8196, 0.8196,  ..., 0.7608, 0.7569, 0.7529],\n",
      "          ...,\n",
      "          [0.8431, 0.7843, 0.6235,  ..., 0.5412, 0.7176, 0.7843],\n",
      "          [0.5804, 0.3765, 0.2667,  ..., 0.1686, 0.2784, 0.4549],\n",
      "          [0.2510, 0.2275, 0.2314,  ..., 0.1412, 0.1412, 0.1529]],\n",
      "\n",
      "         [[0.6392, 0.6353, 0.6314,  ..., 0.5686, 0.5647, 0.5647],\n",
      "          [0.6392, 0.6353, 0.6314,  ..., 0.5686, 0.5647, 0.5647],\n",
      "          [0.6431, 0.6392, 0.6353,  ..., 0.5686, 0.5647, 0.5647],\n",
      "          ...,\n",
      "          [0.6314, 0.5843, 0.4784,  ..., 0.3961, 0.5255, 0.5569],\n",
      "          [0.4549, 0.3098, 0.2549,  ..., 0.1412, 0.2039, 0.3294],\n",
      "          [0.2392, 0.2510, 0.2510,  ..., 0.1333, 0.1216, 0.1294]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0.0667, 0.0510, 0.0667,  ..., 0.0667, 0.0392, 0.0392],\n",
      "          [0.0667, 0.0510, 0.0667,  ..., 0.0667, 0.0392, 0.0392],\n",
      "          [0.0667, 0.0510, 0.0667,  ..., 0.0706, 0.0431, 0.0353],\n",
      "          ...,\n",
      "          [0.8000, 0.7412, 0.4510,  ..., 0.5647, 0.7647, 0.8549],\n",
      "          [0.8196, 0.7176, 0.3765,  ..., 0.7412, 0.8549, 0.8784],\n",
      "          [0.7647, 0.6275, 0.3294,  ..., 0.8118, 0.7804, 0.8275]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0039,  ..., 0.0039, 0.0039, 0.0039],\n",
      "          [0.0000, 0.0000, 0.0039,  ..., 0.0039, 0.0039, 0.0039],\n",
      "          [0.0000, 0.0000, 0.0039,  ..., 0.0078, 0.0039, 0.0039],\n",
      "          ...,\n",
      "          [0.5294, 0.4824, 0.3137,  ..., 0.3725, 0.5451, 0.6431],\n",
      "          [0.5294, 0.4706, 0.2471,  ..., 0.6078, 0.6314, 0.6784],\n",
      "          [0.4667, 0.3804, 0.2000,  ..., 0.7608, 0.6510, 0.5882]],\n",
      "\n",
      "         [[0.0078, 0.0000, 0.0078,  ..., 0.0000, 0.0000, 0.0039],\n",
      "          [0.0078, 0.0000, 0.0039,  ..., 0.0000, 0.0000, 0.0039],\n",
      "          [0.0078, 0.0000, 0.0078,  ..., 0.0039, 0.0039, 0.0039],\n",
      "          ...,\n",
      "          [0.2784, 0.2667, 0.2353,  ..., 0.2510, 0.4235, 0.5098],\n",
      "          [0.2745, 0.2627, 0.1686,  ..., 0.3569, 0.5059, 0.5529],\n",
      "          [0.2235, 0.2039, 0.1176,  ..., 0.4471, 0.3843, 0.4392]]],\n",
      "\n",
      "\n",
      "        [[[0.4196, 0.5020, 0.5765,  ..., 0.2667, 0.3412, 0.4196],\n",
      "          [0.3843, 0.4706, 0.5490,  ..., 0.1294, 0.0980, 0.1020],\n",
      "          [0.4431, 0.5255, 0.5529,  ..., 0.1529, 0.1137, 0.0824],\n",
      "          ...,\n",
      "          [0.4667, 0.4549, 0.4824,  ..., 0.6157, 0.6549, 0.6863],\n",
      "          [0.4667, 0.4784, 0.5020,  ..., 0.6392, 0.6745, 0.7098],\n",
      "          [0.4824, 0.5176, 0.5294,  ..., 0.6784, 0.7098, 0.7294]],\n",
      "\n",
      "         [[0.3059, 0.3725, 0.4314,  ..., 0.2627, 0.3412, 0.4314],\n",
      "          [0.3020, 0.3725, 0.4353,  ..., 0.1255, 0.1020, 0.1098],\n",
      "          [0.4118, 0.4745, 0.4824,  ..., 0.1412, 0.1176, 0.0941],\n",
      "          ...,\n",
      "          [0.4784, 0.4706, 0.4745,  ..., 0.4314, 0.4588, 0.4863],\n",
      "          [0.4706, 0.4745, 0.4706,  ..., 0.4588, 0.4863, 0.5137],\n",
      "          [0.4863, 0.4941, 0.4824,  ..., 0.4941, 0.5176, 0.5569]],\n",
      "\n",
      "         [[0.2706, 0.3098, 0.3451,  ..., 0.2471, 0.3490, 0.4588],\n",
      "          [0.2588, 0.3216, 0.3725,  ..., 0.1176, 0.0863, 0.0941],\n",
      "          [0.3961, 0.4588, 0.4627,  ..., 0.1216, 0.1020, 0.0824],\n",
      "          ...,\n",
      "          [0.4784, 0.4745, 0.4549,  ..., 0.2706, 0.2941, 0.3137],\n",
      "          [0.4588, 0.4588, 0.4431,  ..., 0.2941, 0.3098, 0.3294],\n",
      "          [0.4431, 0.4392, 0.4196,  ..., 0.3294, 0.3451, 0.3961]]],\n",
      "\n",
      "\n",
      "        [[[0.8667, 0.8588, 0.8431,  ..., 0.8980, 0.8549, 0.7882],\n",
      "          [0.8588, 0.8588, 0.8471,  ..., 0.8902, 0.8392, 0.8078],\n",
      "          [0.8078, 0.8157, 0.8275,  ..., 0.8863, 0.8039, 0.8157],\n",
      "          ...,\n",
      "          [0.6588, 0.6745, 0.6745,  ..., 0.7529, 0.7490, 0.7490],\n",
      "          [0.6118, 0.5647, 0.5059,  ..., 0.7529, 0.7490, 0.7490],\n",
      "          [0.3020, 0.2784, 0.2471,  ..., 0.7529, 0.7490, 0.7490]],\n",
      "\n",
      "         [[0.2667, 0.3412, 0.4431,  ..., 0.7020, 0.5255, 0.2392],\n",
      "          [0.4784, 0.4784, 0.5020,  ..., 0.6588, 0.4314, 0.2196],\n",
      "          [0.5490, 0.4941, 0.4588,  ..., 0.6157, 0.3294, 0.2196],\n",
      "          ...,\n",
      "          [0.5137, 0.5059, 0.4784,  ..., 0.7922, 0.7882, 0.7882],\n",
      "          [0.4588, 0.4196, 0.3686,  ..., 0.7922, 0.7882, 0.7882],\n",
      "          [0.2588, 0.2392, 0.2039,  ..., 0.7922, 0.7882, 0.7882]],\n",
      "\n",
      "         [[0.1529, 0.2353, 0.3216,  ..., 0.6314, 0.4235, 0.1216],\n",
      "          [0.4039, 0.4078, 0.4275,  ..., 0.5608, 0.3255, 0.0824],\n",
      "          [0.5176, 0.4392, 0.3961,  ..., 0.5176, 0.2235, 0.0863],\n",
      "          ...,\n",
      "          [0.3647, 0.3412, 0.2980,  ..., 0.8314, 0.8275, 0.8275],\n",
      "          [0.2902, 0.2667, 0.2314,  ..., 0.8314, 0.8275, 0.8275],\n",
      "          [0.1686, 0.1569, 0.1373,  ..., 0.8275, 0.8235, 0.8235]]]]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1])]\n"
     ]
    }
   ],
   "source": [
    "a, b = CelabA_loader()\n",
    "for x in a:\n",
    "    print(x)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# util function mostly for visualization purpose\n",
    "\n",
    "\n",
    "def plot_ELBO_curve(generated, train_list, test_list):\n",
    "    fig = plt.figure()       \n",
    "    plt.plot(train_list, 'r-', label='train ELBO')\n",
    "    plt.plot(test_list, 'r--', label='test ELBO')\n",
    "    plt.legend()\n",
    "    plt.savefig('plots/'+generated+'/ELBO_curves.png')\n",
    "    plt.close()\n",
    "\n",
    "def plot_test_images(sample_hat, generated, n, height=img_size, width=img_size):\n",
    "    sample_hat = sample_hat.view(-1, 3, height, width)\n",
    "    grid = save_image(sample_hat, filename=\"plots/\"+generated+\"/test_images.png\", nrow=n, padding=0)\n",
    "    \n",
    "def plot_latent_traverse(model, image_size, traverse_dim, generated, z_mu, intNumX1=7, n=5):\n",
    "    x1s = np.linspace(-3.0, 3.0, intNumX1, dtype=np.float32)\n",
    "    dist = torch.distributions.normal.Normal(loc=0, scale=1)    \n",
    "    canvas = np.zeros((image_size * n, image_size * intNumX1, 3))\n",
    "    \n",
    "    for j in range(n):\n",
    "        for i, x1 in enumerate(x1s):\n",
    "            z_mu[j][traverse_dim] = torch.Tensor([x1])\n",
    "            z_mu = z_mu.to(device)\n",
    "            z = model(z_mu[j]).detach().to(torch.device(\"cpu\"))\n",
    "            z = z.view(3, image_size, image_size)\n",
    "            z = z.permute(1,2,0).numpy()\n",
    "            canvas[image_size*(n-j-1):image_size*(n-j), image_size*i:image_size*(i+1), :] = z\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(canvas)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"plots/\"+generated+\"/latent/latent_traverses_{}.png\".format(traverse_dim), bbox_inches='tight')\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BetaVAE model structure\n",
    "\n",
    "\n",
    "class View(nn.Module):\n",
    "    def __init__(self, size):\n",
    "        super(View, self).__init__()\n",
    "        self.size = size\n",
    "\n",
    "    def forward(self, tensor):\n",
    "        return tensor.view(self.size)\n",
    "\n",
    "\n",
    "class BetaVAE(nn.Module):\n",
    "    def __init__(self, generated='Gaussian', mode='learn'):\n",
    "        super(BetaVAE, self).__init__()\n",
    "        self.generated = generated\n",
    "        self.mode = mode\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.encoder = nn.Sequential(nn.Conv2d(3, 32, 4, stride=2, padding=1),  # B*32*32*32\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.Conv2d(32, 32, 4, stride=2, padding=1),  # B*32*16*16\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.Conv2d(32, 64, 4, stride=2, padding=1),  # B*64*8*8\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.Conv2d(64, 64, 4, stride=2, padding=1),  # B*64*4*4\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.Conv2d(64, 256, 4),  # B*256*1*1\n",
    "                                     nn.ReLU(),\n",
    "                                     View(size=(-1, 256)),  # B*256\n",
    "                                     nn.Linear(256, lat_dim*2))\n",
    "\n",
    "        self.decoder = nn.Sequential(nn.Linear(lat_dim, 256),\n",
    "                                     View((-1, 256, 1, 1)),  # B*256*1*1\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.ConvTranspose2d(256, 64, 4),  # B*64*4*4\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.ConvTranspose2d(64, 64, 4, stride=2, padding=1),  # B*64*8*8\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.ConvTranspose2d(64, 32, 4, stride=2, padding=1),  # B*32*16*16\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.ConvTranspose2d(32, 32, 4, stride=2, padding=1),  # B*32*32*32\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.ConvTranspose2d(32, 6, 4, stride=2, padding=1))   # B*6*64*64\n",
    "\n",
    "    def reparametrize(self, z_mu, z_log_var):\n",
    "        std = torch.exp(0.5 * z_log_var)\n",
    "        eps = torch.randn(std.size()).to(device)\n",
    "        return z_mu + std * eps\n",
    "\n",
    "    def encoderNet(self, x):\n",
    "        code = self.encoder(x)\n",
    "        z_mu = code[:, :lat_dim]\n",
    "        z_log_var = code[:, lat_dim:]\n",
    "        z = self.reparametrize(z_mu, z_log_var)\n",
    "        self.kl = -0.5 * ((1 + z_log_var) - z_mu * z_mu - torch.exp(z_log_var)).mean(dim=0).sum()\n",
    "        return z\n",
    "\n",
    "    def decoderNet(self, z):\n",
    "        h = self.decoder(z)\n",
    "        if self.generated == 'Bernoulli':\n",
    "            h_ = h[:, :3, :, :]  \n",
    "            self.x_ = self.sigmoid(h_)\n",
    "            \n",
    "        elif self.generated == 'Gaussian':\n",
    "            x_mu = h[:, :3, :, :]\n",
    "            x_log_var = h[:, 3:, :, :]\n",
    "            x_std = torch.exp(0.5 * x_log_var)\n",
    "            self.dist = torch.distributions.normal.Normal(loc=x_mu, scale=x_std)\n",
    "            self.x_ = self.dist.sample()\n",
    "            # For cleaner output, use below mu_estimation\n",
    "            #self.x_ = x_mu \n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.mode == 'learn':\n",
    "            self.z = self.encoderNet(x)\n",
    "            self.decoderNet(self.z)\n",
    "            if self.generated == 'Bernoulli':\n",
    "                self.recon = -(x * torch.log(self.x_ + 1e-10) + (1 - x) * torch.log(1 - self.x_ + 1e-10)).mean(dim=0).sum()\n",
    "            elif self.generated == 'Gaussian':\n",
    "                self.recon = -self.dist.log_prob(x).mean(dim=0).sum()\n",
    "            return self.x_, self.recon, self.kl\n",
    "\n",
    "        elif self.mode == 'generate':\n",
    "            self.decoderNet(x)\n",
    "            return self.x_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n        with torch.no_grad():\\n            cnt = 0\\n            for x, y in test_loader:\\n                cnt += 1\\n                model.eval()\\n                inputs = x.to(device)\\n                new_batch_size = x.size()[0]\\n                inputs = inputs.view(new_batch_size, -1, img_size, img_size)\\n            \\n                _, recon, kl = model(inputs)\\n                loss = recon + beta * kl\\n           \\n                test_loss += loss * new_batch_size / batch_size\\n\\n            test_loss = test_loss / cnt\\n            test_list.append(-test_loss)\\n        \\n        torch.save(model.state_dict(), 'models/'+dist+'/BetaVAE.pt')\\n      \\n        if (epoch+1) % 1 == 0:\\n            print('[Epoch %d] train_loss: %.3f, recon_err: %.3f, kl_div: %.3f, test_loss: %.3f'\\n                  % (epoch+1, train_loss, recon_err, kl_div, test_loss))\\n                \\n    torch.save(inputs, 'data/celebA/samples.pt')\\n    \\n    sample = inputs\\n    sample_hat, _, _ = model(sample)\\n            \\n    plot_test_images(sample_hat.detach(), model.generated, n=10)\\n    \\n    plot_ELBO_curve(model.generated, train_list, test_list)\\n\""
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# main function that is for training the model\n",
    "\n",
    "\n",
    "def CelebA_main(dist='Gaussian'):\n",
    "    train_loader, test_loader = CelabA_loader()\n",
    "    model = BetaVAE(generated=dist).to(device)\n",
    "    model.load_state_dict(torch.load('models/'+dist+'/BetaVAE.pt'))    \n",
    "    model.mode = 'learn'\n",
    "    #for name, param in model.named_parameters():\n",
    "    #    if param.requires_grad:\n",
    "    #        print(name)\n",
    "    \n",
    "    train_list, test_list = [], []\n",
    "    \n",
    "    for epoch in range(n_epoch):\n",
    "        #if (epoch+1) % 200 == 0:\n",
    "        #    lr = lr * 0.1\n",
    "        #    print('current learning rate is ', lr)\n",
    "        optimizer = optim.Adagrad(model.parameters(), lr=lr)\n",
    "        \n",
    "        train_loss, recon_err, kl_div, test_loss = 0.0, 0.0, 0.0, 0.0\n",
    "        cnt = 0\n",
    "        for x, y in train_loader:\n",
    "            plt.imshow(x[0].permute(1,2,0))\n",
    "            \n",
    "            cnt += 1\n",
    "            inputs = x.to(device)\n",
    "            new_batch_size = x.size()[0]\n",
    "            inputs = inputs.view(new_batch_size, -1, img_size, img_size)\n",
    "            \n",
    "            _, recon, kl = model(inputs)\n",
    "            loss = recon + beta * kl\n",
    "            \n",
    "            train_loss += loss * new_batch_size / batch_size\n",
    "            recon_err += recon * new_batch_size / batch_size\n",
    "            kl_div += kl * new_batch_size / batch_size\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            break\n",
    "      \n",
    "        train_loss = train_loss / cnt\n",
    "        recon_err = recon_err / cnt\n",
    "        kl_div = kl_div / cnt\n",
    "        \n",
    "        train_list.append(-train_loss)\n",
    "'''\n",
    "        with torch.no_grad():\n",
    "            cnt = 0\n",
    "            for x, y in test_loader:\n",
    "                cnt += 1\n",
    "                model.eval()\n",
    "                inputs = x.to(device)\n",
    "                new_batch_size = x.size()[0]\n",
    "                inputs = inputs.view(new_batch_size, -1, img_size, img_size)\n",
    "            \n",
    "                _, recon, kl = model(inputs)\n",
    "                loss = recon + beta * kl\n",
    "           \n",
    "                test_loss += loss * new_batch_size / batch_size\n",
    "\n",
    "            test_loss = test_loss / cnt\n",
    "            test_list.append(-test_loss)\n",
    "        \n",
    "        torch.save(model.state_dict(), 'models/'+dist+'/BetaVAE.pt')\n",
    "      \n",
    "        if (epoch+1) % 1 == 0:\n",
    "            print('[Epoch %d] train_loss: %.3f, recon_err: %.3f, kl_div: %.3f, test_loss: %.3f'\n",
    "                  % (epoch+1, train_loss, recon_err, kl_div, test_loss))\n",
    "                \n",
    "    torch.save(inputs, 'data/celebA/samples.pt')\n",
    "    \n",
    "    sample = inputs\n",
    "    sample_hat, _, _ = model(sample)\n",
    "            \n",
    "    plot_test_images(sample_hat.detach(), model.generated, n=10)\n",
    "    \n",
    "    plot_ELBO_curve(model.generated, train_list, test_list)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:1\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Calculated padded input size per channel: (2 x 2). Kernel size: (4 x 4). Kernel size can't be greater than actual input size",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-97-1d3f5c257e3b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mn_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mCelebA_main\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-96-a6b42b48ee14>\u001b[0m in \u001b[0;36mCelebA_main\u001b[0;34m(dist)\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecon\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbeta\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mkl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-95-c80d0beb2716>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'learn'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoderNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoderNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerated\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Bernoulli'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-95-c80d0beb2716>\u001b[0m in \u001b[0;36mencoderNet\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mencoderNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0mz_mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mlat_dim\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mz_log_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlat_dim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    344\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    345\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 346\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Calculated padded input size per channel: (2 x 2). Kernel size: (4 x 4). Kernel size can't be greater than actual input size"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# running part for training BetaVAE model with CelebA dataset\n",
    "\n",
    "\n",
    "if __name__ == '__main__': \n",
    "    print(device)\n",
    "    lr = 1e-4\n",
    "    n_epoch = 1\n",
    "    CelebA_main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1st experiment : drawing a latent traverse of BetaVAE\n",
    "\n",
    "\n",
    "if __name__ == '__main__': \n",
    "    print(device)\n",
    "    model = BetaVAE('Gaussian').to(device)\n",
    "    model.load_state_dict(torch.load('models/Gaussian/BetaVAE_Crop.pt'))\n",
    "\n",
    "    sample = torch.load('data/celebA/samples.pt')\n",
    "\n",
    "    for i in range(lat_dim):    \n",
    "        model.mode = 'generate'\n",
    "        z_mu = model.encoderNet(sample)\n",
    "        plot_latent_traverse(model, img_size, i, model.generated, z_mu)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
